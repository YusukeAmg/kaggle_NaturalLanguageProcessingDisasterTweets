{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "train_df = pd.read_csv('../data/input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetテキストの余計な文字を削除\n",
    "import re\n",
    "\n",
    "def preprocess_text(sentence):\n",
    "    # URL\n",
    "    sentence = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\\s*\", ' ', sentence)\n",
    "    # Hash Tag\n",
    "    #sentence = re.sub(r'#[^\\s]+\\s*', ' ', sentence)\n",
    "    # アルファベット以外\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # 単一文字\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    # 連続する空白を1つの空白に\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "stop_words = list(gsp.STOPWORDS)\n",
    "stop_words.remove('fire')\n",
    "\n",
    "def gensim_preprocess(sentence):\n",
    "    sentence = sentence.lower()# 小文字化\n",
    "    sentence = re.sub(r'(https?://[a-zA-Z0-9.-]*)', ' ', sentence)# URL除去\n",
    "    #sentence = gsp.strip_tags(sentence)# HTMLタグ除去\n",
    "    sentence = gsp.strip_punctuation(sentence)# 句読点を空白に変える\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)# アルファベット以外\n",
    "    sentence = gsp.strip_multiple_whitespaces(sentence)# 複数空白、タブ、改行を1つの空白にする\n",
    "    sentence = gsp.strip_numeric(sentence)# 数字を除く\n",
    "    sentence = ' '.join(word for word in sentence.split(' ') if word not in stop_words)# stop words\n",
    "    sentence = gsp.strip_short(sentence, minsize=3)# 指定した長さ(deault:3)より短い単語を除く\n",
    "    sentence = gsp.stem_text(sentence) # 単語から語幹を除く\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1   4     NaN      NaN              Forest fire near La Ronge Sask Canada   \n",
       "2   5     NaN      NaN  All residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN   people receive wildfires evacuation orders in...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak allah forgiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN                 deed reason earthquak allah forgiv   \n",
       "1   4     NaN      NaN                  forest fire near rong sask canada   \n",
       "2   5     NaN      NaN  resid ask shelter place notifi offic evacu she...   \n",
       "3   6     NaN      NaN        peopl receiv wildfir evacu order california   \n",
       "4   7     NaN      NaN  got sent photo rubi alaska smoke wildfir pour ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# テキストを前処理\n",
    "train_re = train_df.copy()\n",
    "train_gen = train_df.copy()\n",
    "\n",
    "train_re[\"text\"] = train_re[\"text\"].apply(lambda x: preprocess_text(x))\n",
    "train_gen[\"text\"] = train_gen[\"text\"].apply(lambda x: gensim_preprocess(x))\n",
    "display(train_re.head())\n",
    "display(train_gen.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "re preprocessed train data shape: (7613, 16191)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "gensim preprocessed train data shape: (7613, 18280)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "tr_re_count_vec = count_vectorizer.fit_transform(train_re[\"text\"])\n",
    "tr_gen_count_vec = count_vectorizer.fit_transform(train_gen[\"text\"])\n",
    "## we use .todense() here because these vectors are \"sparse\"\n",
    "print(train_df[\"text\"][0])\n",
    "print(\"re preprocessed train data shape:\", tr_re_count_vec.todense().shape)\n",
    "print(tr_re_count_vec.todense())\n",
    "print(\"gensim preprocessed train data shape:\", tr_gen_count_vec.todense().shape)\n",
    "print(tr_gen_count_vec.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_re_transformer:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "tfidf_gen_transformer:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "re preprocessed data shape: (7613, 16191)\n",
      "tfidf_re_vectorizer:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "gensim preprocessed data shape: (7613, 18280)\n",
      "tfidf_gen_vectorizer:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Tf-Idf Vectorizer(Tf-Idf transformer)\n",
    "# TfidfTransformer is used on an existing count matrix such as one returned by CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_re_trans = tfidf_transformer.fit_transform(tr_re_count_vec)\n",
    "tfidf_gen_trans = tfidf_transformer.fit_transform(tr_gen_count_vec)\n",
    "tr_re_tfidf_vec = tfidf_vectorizer.fit_transform(train_re[\"text\"])\n",
    "tr_gen_tfidf_vec = tfidf_vectorizer.fit_transform(train_gen[\"text\"])\n",
    "\n",
    "print(\"tfidf_re_transformer:\\n\", tfidf_re_trans.todense())\n",
    "print(\"\\ntfidf_gen_transformer:\\n\", tfidf_gen_trans.todense())\n",
    "\n",
    "print(\"\\nre preprocessed data shape:\", tr_re_tfidf_vec.shape)\n",
    "print(\"tfidf_re_vectorizer:\\n\", tr_re_tfidf_vec.todense())\n",
    "\n",
    "print(\"\\ngensim preprocessed data shape:\", tr_gen_tfidf_vec.shape)\n",
    "print(\"tfidf_gen_vectorizer:\\n\", tr_gen_tfidf_vec.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "re preprocessed data shape: (7613, 768)\n",
      "[[-0.09965673  1.0299886   0.85591394 ...  0.17161681 -0.75642484\n",
      "   0.27112168]\n",
      " [-0.06845954  0.9203234   0.1360512  ... -0.61632764  0.07919553\n",
      "   0.2655284 ]\n",
      " [-0.16675152  0.73107177  2.1624925  ...  0.44667816 -0.89984876\n",
      "  -0.173441  ]\n",
      " ...\n",
      " [ 0.17871219  0.25007972  0.64667475 ... -1.1354394   0.4887453\n",
      "   0.2994783 ]\n",
      " [-0.46670738 -0.23355019 -0.33531058 ... -0.5660839  -0.8959852\n",
      "  -0.34056386]\n",
      " [ 0.63955176  0.12620305  0.4097528  ... -0.7496225   0.9582164\n",
      "  -0.6429042 ]]\n",
      "\n",
      "gensim preprocessed data shape: (7613, 768)\n",
      "[[ 0.06911088  0.78569794  0.97117573 ... -0.44359168 -0.5179217\n",
      "   0.39473927]\n",
      " [ 0.01331958  0.91980946  0.24482374 ... -0.53480923  0.13305727\n",
      "   0.38670892]\n",
      " [ 0.1850915   0.34008476  1.6238809  ...  0.3299464  -1.015084\n",
      "   0.33661366]\n",
      " ...\n",
      " [ 0.275324    0.06075098  0.8673379  ... -0.69132257  0.43372035\n",
      "   0.13150543]\n",
      " [ 0.21746318  0.18880795  0.5193     ... -0.7530516  -1.0929471\n",
      "  -0.48772135]\n",
      " [ 0.22010697  0.26909998  1.4243352  ... -0.53428435  0.7148596\n",
      "  -0.2682906 ]]\n"
     ]
    }
   ],
   "source": [
    "# BERT vectorize\n",
    "# [referece](https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "tr_re_bert_vec = model.encode(train_re['text'])\n",
    "tr_gen_bert_vec = model.encode(train_gen['text'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(\"re preprocessed data shape:\", tr_re_bert_vec.shape)\n",
    "print(tr_re_bert_vec)\n",
    "\n",
    "print(\"\\ngensim preprocessed data shape:\", tr_gen_bert_vec.shape)\n",
    "print(tr_gen_bert_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare vectors\n",
    "using classifier:Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count vector scores(re)\n",
      "0\t0.6098\n",
      "1\t0.5595\n",
      "2\t0.6203\n",
      "score average: 0.5966\n",
      "count vector scores(gensim)\n",
      "0\t0.5869\n",
      "1\t0.5491\n",
      "2\t0.6086\n",
      "score average: 0.5815\n",
      "\n",
      "tf-idf vector scores(re)\n",
      "0\t0.6330\n",
      "1\t0.6037\n",
      "2\t0.6812\n",
      "score average: 0.6393\n",
      "tf-idf vector scores(gensim)\n",
      "0\t0.5987\n",
      "1\t0.5748\n",
      "2\t0.6370\n",
      "score average: 0.6035\n",
      "\n",
      "bert vector scores(re)\n",
      "0\t0.7289\n",
      "1\t0.7091\n",
      "2\t0.7642\n",
      "score average: 0.7341\n",
      "bert vector scores(gensim)\n",
      "0\t0.6748\n",
      "1\t0.6422\n",
      "2\t0.7245\n",
      "score average: 0.6805\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "clf = linear_model.RidgeClassifier()\n",
    "\n",
    "# Count Vector\n",
    "scores_re_count_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_re_count_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "scores_gen_count_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_gen_count_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "# Tf-Idf Vector\n",
    "scores_re_tfidf_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_re_tfidf_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "scores_gen_tfidf_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_gen_tfidf_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "# sentence Transformer\n",
    "scores_re_bert_vec = model_selection.cross_val_score(\n",
    "    clf,\n",
    "    tr_re_bert_vec,\n",
    "    train_df['target'],\n",
    "    cv=3,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "scores_gen_bert_vec = model_selection.cross_val_score(\n",
    "    clf,\n",
    "    tr_gen_bert_vec,\n",
    "    train_df['target'],\n",
    "    cv=3,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"count vector scores(re)\")\n",
    "for i, score in enumerate(scores_re_count_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_re_count_vec.mean():.4f}\")\n",
    "print(\"count vector scores(gensim)\")\n",
    "for i, score in enumerate(scores_gen_count_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_gen_count_vec.mean():.4f}\")\n",
    "\n",
    "print(\"\\ntf-idf vector scores(re)\")\n",
    "for i, score in enumerate(scores_re_tfidf_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_re_tfidf_vec.mean():.4f}\")\n",
    "print(\"tf-idf vector scores(gensim)\")\n",
    "for i, score in enumerate(scores_gen_tfidf_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_gen_tfidf_vec.mean():.4f}\")\n",
    "\n",
    "print(\"\\nbert vector scores(re)\")\n",
    "for i, score in enumerate(scores_re_bert_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_re_bert_vec.mean():.4f}\")\n",
    "print(\"bert vector scores(gensim)\")\n",
    "for i, score in enumerate(scores_gen_bert_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_gen_bert_vec.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "stemming, remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "stemming, remove stop words:\n",
      "  deed reason earthquak allah forgiv\n",
      "preprocessed train text:\n",
      " 0                      deed reason earthquak allah forgiv\n",
      "1                            forest near rong sask canada\n",
      "2       resid ask shelter place notifi offic evacu she...\n",
      "3             peopl receiv wildfir evacu order california\n",
      "4       got sent photo rubi alaska smoke wildfir pour ...\n",
      "                              ...                        \n",
      "7608    giant crane hold bridg collaps nearbi home htt...\n",
      "7609    aria ahrari thetawniest control wild fire cali...\n",
      "7610                    utc volcano hawaii http zdtoydebj\n",
      "7611    polic investig bike collid car littl portug bi...\n",
      "7612    latest home raze northern california wildfir a...\n",
      "Name: text, Length: 7613, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# gensim preprocessing(stemming&remove stop words)\n",
    "from gensim.parsing.preprocessing import preprocess_documents, preprocess_string\n",
    "\n",
    "print(\"original:\\n \", train_df[\"text\"][0])\n",
    "print(\"stemming, remove stop words:\\n \", ' '.join(preprocess_documents(train_df['text'])[0]))\n",
    "preprocess_doc = train_df[\"text\"].apply(lambda x:' '.join(preprocess_string(x)))\n",
    "print(\"preprocessed train text:\\n\", preprocess_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count vector scores\n",
      "0\t0.5879\n",
      "1\t0.5564\n",
      "2\t0.6357\n",
      "score average: 0.5933\n",
      "\n",
      "tf-idf vector scores\n",
      "0\t0.5975\n",
      "1\t0.5757\n",
      "2\t0.6537\n",
      "score average: 0.6090\n",
      "\n",
      "bert vector scores\n",
      "0\t0.6790\n",
      "1\t0.6413\n",
      "2\t0.7266\n",
      "score average: 0.6823\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from sklearn import linear_model, feature_extraction, model_selection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "texts = train_df[\"text\"].apply(lambda x:' '.join(preprocess_string(x)))\n",
    "\n",
    "clf = linear_model.RidgeClassifier()\n",
    "\n",
    "# Count Vector\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "tr_prcssd_count_vec = count_vectorizer.fit_transform(texts)\n",
    "\n",
    "scores_count_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_prcssd_count_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "# Tf-Idf Vector\n",
    "tfidf_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "tr_prcssd_tfidf_vec = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "scores_tfidf_vec = model_selection.cross_val_score(\n",
    "    clf, \n",
    "    tr_prcssd_tfidf_vec, \n",
    "    train_df[\"target\"], \n",
    "    cv=3, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "# sentence Transformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "tr_prcssd_bert_vec = model.encode(texts)\n",
    "\n",
    "scores_bert_vec = model_selection.cross_val_score(\n",
    "    clf,\n",
    "    tr_prcssd_bert_vec,\n",
    "    train_df['target'],\n",
    "    cv=3,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(f\"count vector scores\")\n",
    "for i, score in enumerate(scores_count_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_count_vec.mean():.4f}\\n\")\n",
    "\n",
    "print(f\"tf-idf vector scores\")\n",
    "for i, score in enumerate(scores_tfidf_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_tfidf_vec.mean():.4f}\\n\")\n",
    "\n",
    "print(f\"bert vector scores\")\n",
    "for i, score in enumerate(scores_bert_vec):print(f\"{i}\\t{score:.4f}\")\n",
    "print(f\"score average: {scores_bert_vec.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hel', 'rld'], ['weather', 'todai', 'isn']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_documents(\n",
    "    [\"<i>Hel 9lo</i> <b>Wo9 rld</b>!\", \"Th3     Weather_is really g00d today, isn't it?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hel', 'rld', 'weather', 'todai', 'isn']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_string(\n",
    "    \"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3  fire    Weather_is really g00d today, isn't it?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hel',\n",
       " '9lo',\n",
       " 'wo9',\n",
       " 'rld',\n",
       " 'th3',\n",
       " 'weather',\n",
       " 'is',\n",
       " 'really',\n",
       " 'g00d',\n",
       " 'today',\n",
       " 'isn',\n",
       " 't',\n",
       " 'it']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation\n",
    "s = \"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3     Weather_is really g00d today, isn't it?\"\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation]\n",
    "preprocess_string(s, CUSTOM_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
